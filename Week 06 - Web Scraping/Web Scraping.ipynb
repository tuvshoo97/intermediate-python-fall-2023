{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Web Scraping in Python\n",
    "\n",
    "Web scraping is the process of collecting and parsing raw data from the Web, and the Python community has come up with some pretty powerful web scraping tools.\n",
    "Many disciplines, such as data science, business intelligence, and investigative reporting, can benefit enormously from collecting and analyzing data from websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape and Parse texts from Websites\n",
    "Collecting data from websites using an automated process is known as web scraping. Some websites explicitly forbid users from scraping their data with automated tools.\n",
    "\n",
    "**Websites have two main reasons to not allow web scraping**\n",
    "1. To protect its data. For example: Google maps do not allow users to request too many results in a minute.\n",
    "2. To prevent overuse of their servers. When bots start sending many requests website's servers slow down and thus other users will have slower connection to the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful package for web scraping that you can find in Python’s standard library is [urllib](https://docs.python.org/3/library/urllib.html), which contains tools for working with URLs.\n",
    "**urllib** is for opening and reading URLs.\n",
    "\n",
    "#### Let's look at the example and use **urllib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "url = \"http://olympus.realpython.org/profiles/aphrodite\"\n",
    "page = urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the HTML from the page:\n",
    "1. Use html's read method to return sequence of bytes\n",
    "2. Use decode method on 1st result to decode bytes to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_by = page.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Profile: Aphrodite</title>\n",
      "</head>\n",
      "<body bgcolor=\"yellow\">\n",
      "<center>\n",
      "<br><br>\n",
      "<img src=\"/static/aphrodite.gif\" />\n",
      "<h2>Name: Aphrodite</h2>\n",
      "<br><br>\n",
      "Favorite animal: Dove\n",
      "<br><br>\n",
      "Favorite color: Red\n",
      "<br><br>\n",
      "Hometown: Mount Olympus\n",
      "</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = html_by.decode(\"utf-8\")\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try to get the title of the webpage\n",
    "1. We need to get the index of the **\\<title>**, and because title tags strings have been counted we need to add it to the index. \n",
    "2. Find the index of the closing **\\<title>** tag\n",
    "3. Get the title by slicing the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n<head>\\n<title>Profile: Aphrodite</title>\\n</head>\\n<body bgcolor=\"yellow\">\\n<center>\\n<br><br>\\n<img src=\"/static/aphrodite.gif\" />\\n<h2>Name: Aphrodite</h2>\\n<br><br>\\nFavorite animal: Dove\\n<br><br>\\nFavorite color: Red\\n<br><br>\\nHometown: Mount Olympus\\n</center>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.find(\"<title>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<title>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html[14:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_index = html.find(\"<title>\")\n",
    "start_index = title_index + len(\"<title>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(start_index)\n",
    "print(title_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "end_index = html.find(\"</title>\")\n",
    "print(end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: Aphrodite\n"
     ]
    }
   ],
   "source": [
    "title = html[start_index:end_index]\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is a lot of work just to get the title of the page. In the real world, websites are much more complex and complicated. We can use find many dedicated tools for html scraping but the most powerful and popular library for Python is [**Beautiful soup**](https://www.crummy.com/software/BeautifulSoup/)\n",
    "\n",
    "Beautiful Soup is a Python library designed for quick turnaround projects like screen-scraping.\n",
    "\n",
    "**Run the command below to install**:\n",
    "```bash\n",
    "conda install beautifulsoup4\n",
    "pip install beautifulsoup4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = \"http://olympus.realpython.org/profiles/aphrodite\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>Profile: Aphrodite</title>\n",
       "</head>\n",
       "<body bgcolor=\"yellow\">\n",
       "<center>\n",
       "<br/><br/>\n",
       "<img src=\"/static/aphrodite.gif\"/>\n",
       "<h2>Name: Aphrodite</h2>\n",
       "<br/><br/>\n",
       "Favorite animal: Dove\n",
       "<br/><br/>\n",
       "Favorite color: Red\n",
       "<br/><br/>\n",
       "Hometown: Mount Olympus\n",
       "</center>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: Aphrodite'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"h2\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Aphrodite\n"
     ]
    }
   ],
   "source": [
    "for x in soup.find_all(\"h2\"):\n",
    "    print(x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example above does three things\n",
    "1. Opens up a page using **urlopen** from **urllib.request**\n",
    "2. Reads and decodes the page and saves as a variable\n",
    "3. Creates a BeautifulSoup object and assigns it to the soup variable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup objects have a **.get_text()** method that can be used to extract all the text from the document and automatically remove any HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Profile: Aphrodite\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name: Aphrodite\n",
      "\n",
      "Favorite animal: Dove\n",
      "\n",
      "Favorite color: Red\n",
      "\n",
      "Hometown: Mount Olympus\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the title of the page, you can use **.title**, and **.string** to get the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Profile: Aphrodite'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Profile: Aphrodite</title>\n",
      "Profile: Aphrodite\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "print(soup.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use **find()** to find the tags you want and get the source attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = soup.find(\"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<img src=\"/static/aphrodite.gif\"/>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/static/aphrodite.gif'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://olympus.realpython.org/static/aphrodite.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise your web scraping on Unegui.mn\n",
    "1. Go to https://www.unegui.mn/avto-mashin/-avtomashin-zarna/, Use inspection tool on your browser to see the html tags and attributes.\n",
    "2. Scrape all the listing's **title** and **price**. Scrape only the first page!\n",
    "3. Save your listings as a pandas DataFrame\n",
    "Example below illustrates the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titles = ['Toyota FJ Cruiser, 2012/2020', 'Honda Crossroad, 2009/2019']\n",
    "prices = ['62 сая', '17 сая']\n",
    "results = pd.DataFrame([titles, prices], columns=['titles', 'prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "announcement-block__price _verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://www.unegui.mn/kompyuter-busad/notebook/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.find_all(\"div\", {\"class\": \"announcement-block__price _verified\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"announcement-block__price _verified\" itemprop=\"offers\" itemscope=\"\" itemtype=\"http://schema.org/Offer\">\n",
       "<meta content=\"Acer aspire e-5 ram-4gb hard-250gb hdd inch-15.6\" itemprop=\"name\">\n",
       "<meta content=\"Улаанбаатар\" itemprop=\"areaServed\">\n",
       "<meta content=\"MNT\" itemprop=\"priceCurrency\"/>\n",
       "<meta content=\"890000.00\" itemprop=\"price\"/>\n",
       "              890,000 <b>₮</b>\n",
       "<span class=\"verified\" title=\"Баталгаажсан хэрэглэгч\"></span>\n",
       "</meta></meta></div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['title','price'])\n",
    "\n",
    "for url in urls:\n",
    "    soup = BeautifulSoup(response.content)\n",
    "    results = soup.find_all(\"div\", {\"class\": \"announcement-block__price _verified\"})\n",
    "    for item in results:\n",
    "        title = item.find(\"meta\", {\"itemprop\":\"name\"})['content']\n",
    "        price = item.find(\"meta\", {\"itemprop\":\"price\"})['content']\n",
    "        df = df.append({'title':title,'price':price}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung i5 8-р үе ram-8gb hard-128gb ssd+500gb...</td>\n",
       "      <td>1690000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell precision-5520 i7 7820hq ram-16gb hard-25...</td>\n",
       "      <td>2690000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hp spectre x360 convertible i5 8-р үе ram-8gb ...</td>\n",
       "      <td>2490000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell gamer g7 i7 9-р үе rtx2060 17.3</td>\n",
       "      <td>3890000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell latitude e-5270 i3 6-р үе ram-8gb hard-25...</td>\n",
       "      <td>890000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Acer 17.3 i5-10th gen 8gb ram 128gb ssd 500gb hdd</td>\n",
       "      <td>2000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Dell i3 8gb ram 128gb ssd</td>\n",
       "      <td>1750000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Hp omen x i7-8 16gb 128gb+1000gb rtx 2070 15.6...</td>\n",
       "      <td>4090000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Acer nitro 5 i7 10-р үе 8gb 128gb+1000gb hdd 1...</td>\n",
       "      <td>3490000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Hp omen x i7 9-р үе rtx2080</td>\n",
       "      <td>4690000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title       price\n",
       "0    Samsung i5 8-р үе ram-8gb hard-128gb ssd+500gb...  1690000.00\n",
       "1    Dell precision-5520 i7 7820hq ram-16gb hard-25...  2690000.00\n",
       "2    Hp spectre x360 convertible i5 8-р үе ram-8gb ...  2490000.00\n",
       "3                 Dell gamer g7 i7 9-р үе rtx2060 17.3  3890000.00\n",
       "4    Dell latitude e-5270 i3 6-р үе ram-8gb hard-25...   890000.00\n",
       "..                                                 ...         ...\n",
       "120  Acer 17.3 i5-10th gen 8gb ram 128gb ssd 500gb hdd  2000000.00\n",
       "121                          Dell i3 8gb ram 128gb ssd  1750000.00\n",
       "122  Hp omen x i7-8 16gb 128gb+1000gb rtx 2070 15.6...  4090000.00\n",
       "123  Acer nitro 5 i7 10-р үе 8gb 128gb+1000gb hdd 1...  3490000.00\n",
       "124                        Hp omen x i7 9-р үе rtx2080  4690000.00\n",
       "\n",
       "[125 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'890000.00'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].find_all(\"meta\", {\"itemprop\":\"price\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get a list of URLs to scrape\n",
    "2. Loop through the URLs\n",
    "3. Inside that loop, loop through the listings (65 per page)\n",
    "4. Grab the data you need (title and price for 65 listings)\n",
    "5. Append it to a dataframe\n",
    "6. Go the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for number in range(1,72):\n",
    "    urls.append(f'https://www.unegui.mn/kompyuter-busad/notebook/?page={number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.zangia.mn/job/_sygeyd3008'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, timeout=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div><b>Байршил</b><span>Улаанбаатар хот, Сонгинохайрхан дүүрэг</span></div>,\n",
       " <div><b>Салбар</b><span>Банк, санхүү, нягтлан бодох бүртгэл</span></div>,\n",
       " <div><b>Түвшин</b><span>Дунд шатны удирдлага</span></div>,\n",
       " <div><b>Төрөл</b><span>Бүтэн цагийн</span></div>,\n",
       " <div><b>Цалин</b><span>1,500,000 - 1,800,000</span></div>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"div\", {\"class\": \"details\"})[0].find_all(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_div = soup.find_all(\"div\", {\"class\": \"details\"})[0].find_all(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = soup.find_all(\"div\", {\"class\": \"details\"})[0].find_all(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div><b>Байршил</b><span>Улаанбаатар хот, Сонгинохайрхан дүүрэг</span></div>,\n",
       " <div><b>Салбар</b><span>Банк, санхүү, нягтлан бодох бүртгэл</span></div>,\n",
       " <div><b>Түвшин</b><span>Дунд шатны удирдлага</span></div>,\n",
       " <div><b>Төрөл</b><span>Бүтэн цагийн</span></div>,\n",
       " <div><b>Цалин</b><span>1,500,000 - 1,800,000</span></div>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.zangia.mn/job/list/lmt.100/pg.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, timeout=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads = soup.find_all(\"div\", {\"class\": \"ad\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_links = [ad.find(\"a\")['href'] for ad in ads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_links = []\n",
    "for ad in ads:\n",
    "    job_links.append(ad.find(\"a\")['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_links = []\n",
    "for link in links:\n",
    "    if 'job/_' in link['href']:\n",
    "        entry_links.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.zangia.mn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['job/_vn+z9gfpq2',\n",
       " 'job/_ev05qlotmk',\n",
       " 'job/_4aff_s4wpd',\n",
       " 'job/_wc_k+oh-qw',\n",
       " 'job/_bb2sf1qm6v',\n",
       " 'job/_y+81sl4de4',\n",
       " 'job/_9n3t3icdly',\n",
       " 'job/_b0+vlvpjtv',\n",
       " 'job/_1970_zgrm5',\n",
       " 'job/_l1mnuiic_c',\n",
       " 'job/_pi0h0ghq_e',\n",
       " 'job/_w-_8xy-ekk',\n",
       " 'job/_54_lmpebjv',\n",
       " 'job/_qq9_ko9qt2',\n",
       " 'job/_yz8w5387fk',\n",
       " 'job/_klqlvqctyo',\n",
       " 'job/_8u-o8mqgp6',\n",
       " 'job/_23-maw4zz2',\n",
       " 'job/_7+o8m36t-0',\n",
       " 'job/_hqdk93m-7d',\n",
       " 'job/_lbap2gnt53',\n",
       " 'job/_i1m7zekc42',\n",
       " 'job/_2nkvgkb6x5',\n",
       " 'job/_dfuazr7553',\n",
       " 'job/_ok3+pohb66',\n",
       " 'job/_5z4yvm4i-0',\n",
       " 'job/_827c7wv2a3',\n",
       " 'job/_ejv5rq3ymx',\n",
       " 'job/_gobpmz0tly',\n",
       " 'job/_bb0o4xo+fc',\n",
       " 'job/_be51z+fmu0',\n",
       " 'job/_l9ea0lf25l',\n",
       " 'job/_phq7b0v6ni',\n",
       " 'job/_p__c1cigv3',\n",
       " 'job/_bxz5va6nj9',\n",
       " 'job/_ejlarkg9_s',\n",
       " 'job/_puk-g22_il',\n",
       " 'job/_axoxr9j8+w',\n",
       " 'job/_8t4bahd+_3',\n",
       " 'job/_p3late6z6s',\n",
       " 'job/_fbkg90ngn3',\n",
       " 'job/_e180cn88mj',\n",
       " 'job/_0b-d3+82tn',\n",
       " 'job/_c-qg77g_su',\n",
       " 'job/_5chf0vfz7r',\n",
       " 'job/_ahzvlvre_l',\n",
       " 'job/_pvwfay-0xb',\n",
       " 'job/_ti4xdz7f8m',\n",
       " 'job/_m7if4zw433',\n",
       " 'job/_vdwxhe2uhy',\n",
       " 'job/_9xjtwx9zfx',\n",
       " 'job/_qu_qeapdjs',\n",
       " 'job/_vrs6r4cesq',\n",
       " 'job/_gv+i37h-t2',\n",
       " 'job/_v97_pd_a+u',\n",
       " 'job/_z7w_ipecen',\n",
       " 'job/_s-_ru6ef11',\n",
       " 'job/_s-hwa11spu',\n",
       " 'job/_yvqkflpbwc',\n",
       " 'job/_om51jz+tkd',\n",
       " 'job/_e1kz3malcz',\n",
       " 'job/_1rn7nscr4z',\n",
       " 'job/_s-48y_hxur',\n",
       " 'job/_1l2jtr1u92',\n",
       " 'job/_391u4odtss',\n",
       " 'job/_blso-htbh6',\n",
       " 'job/_bck5m_2tx6',\n",
       " 'job/_kmmzp+sdo3',\n",
       " 'job/_2zmtgqvv49',\n",
       " 'job/_171vk5n_nh',\n",
       " 'job/_v11g5ogl9q',\n",
       " 'job/_w25s3qia9l',\n",
       " 'job/_qo2gxcanyx',\n",
       " 'job/_c22w47lla6',\n",
       " 'job/_aukl3dj6xc',\n",
       " 'job/_qtoxulzjkd',\n",
       " 'job/_91060kezp4',\n",
       " 'job/_5qqsc5r0+x',\n",
       " 'job/_nx569+fyrp',\n",
       " 'job/_0js1clcs-n',\n",
       " 'job/_xpu6z5z5ym',\n",
       " 'job/_fl1p7miysg',\n",
       " 'job/_tkun0tpij9',\n",
       " 'job/_74_h6ddnyk',\n",
       " 'job/_0mw-aldkqr',\n",
       " 'job/_bc2gmpr3nb',\n",
       " 'job/_wca+odfw2i',\n",
       " 'job/_kyzwtgp_b2',\n",
       " 'job/_xmdjr+15-j',\n",
       " 'job/_u6ac4vw3a2',\n",
       " 'job/_bb8r_edvmg',\n",
       " 'job/_nplwn+tfos',\n",
       " 'job/_d5lsitflt6',\n",
       " 'job/_v5d41osqkc',\n",
       " 'job/_g-9pvepnlv',\n",
       " 'job/_5j20556m+o',\n",
       " 'job/_o__n98q_ay',\n",
       " 'job/_2xpksic884',\n",
       " 'job/_uk0++_vdzv',\n",
       " 'job/_quo_7uxk+6',\n",
       " 'job/_jbsuupp761',\n",
       " 'job/_09kz8i3-kx',\n",
       " 'job/_il5axym0zl',\n",
       " 'job/_nbp+cdxa9d',\n",
       " 'job/_7ynhu4nyfx',\n",
       " 'job/_uckm+v0gsm',\n",
       " 'job/_9lebt0bpeq',\n",
       " 'job/_o-b277scpg',\n",
       " 'job/_o_k5ev43rh',\n",
       " 'job/_m2glncz6w5',\n",
       " 'job/_3-h1njs7_s',\n",
       " 'job/_orv7iekpzd',\n",
       " 'job/_f895dew059',\n",
       " 'job/_fcyfkuehfr',\n",
       " 'job/_6y+j4or6e6',\n",
       " 'job/_r-t8k8wj5m',\n",
       " 'job/_8u0wlc5pz1']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
